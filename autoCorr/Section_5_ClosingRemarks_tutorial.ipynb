{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/svds_logo.png\" alt=\"SVDS\" width=\"500\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyData San Francisco 2016\n",
    "## Applied Time Series Econometrics in Python (and R) Tutorial\n",
    "\n",
    "### Section 5. Closing Remarks: Practical suggestions and other topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics in this section include\n",
    "\n",
    "- 5.1 Model selection heuristics\n",
    "- 5.2 Material we did not cover\n",
    "- 5.3 Where to go from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Model selection heuristics\n",
    "\n",
    "ARIMA $(p,d,q)$\n",
    "\n",
    "SARIMAX $(p,d,q) \\times (P,D,Q)_{s}$\n",
    "\n",
    "- Examine the time series to understand its characteristics, e.g., trend, seasonality.\n",
    "- Choose an appropriate model form (ARIMA, SARIMA, ARIMAX, SARIMAX).\n",
    "- Check for (unit root) stationarity of the time series.\n",
    "  - Determine whether differencing (informs $d$ and $D$) or other transformation is necessary to make stationary.\n",
    "- Examine ACF and PACF to determine the initial choice of the AR($p$) and MA($q$) model orders, and seasonal $P$ and $Q$ orders if appropriate.\n",
    "- Alternatively, or in addition, fit many models.\n",
    "- Choose a model based on:\n",
    "  - A criterion, e.g., AIC, BIC\n",
    "  - Examination of statistical tests on residuals.\n",
    "  - Out-of-sample forecast error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.tsa.api as smt\n",
    "\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "# Display and Plotting\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x) # pandas\n",
    "np.set_printoptions(precision=5, suppress=True) # numpy\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# seaborn plotting style\n",
    "sns.set(style='ticks', context='poster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_stationarity(timeseries,\n",
    "                      maxlag=None, regression=None, autolag=None,\n",
    "                      window=None, plot=False, verbose=False):\n",
    "    '''\n",
    "    Check unit root stationarity of time series.\n",
    "    \n",
    "    Null hypothesis: the series is non-stationary.\n",
    "    If p >= alpha, the series is non-stationary.\n",
    "    If p < alpha, reject the null hypothesis (has unit root stationarity).\n",
    "    \n",
    "    Original source: http://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/\n",
    "    \n",
    "    Function: http://statsmodels.sourceforge.net/devel/generated/statsmodels.tsa.stattools.adfuller.html\n",
    "    \n",
    "    window argument is only required for plotting rolling functions. Default=4.\n",
    "    '''\n",
    "    \n",
    "    # set defaults (from function page)\n",
    "    if regression is None:\n",
    "        regression = 'c'\n",
    "    \n",
    "    if verbose:\n",
    "        print('Running Augmented Dickey-Fuller test with paramters:')\n",
    "        print('maxlag: {}'.format(maxlag))\n",
    "        print('regression: {}'.format(regression))\n",
    "        print('autolag: {}'.format(autolag))\n",
    "    \n",
    "    if plot:\n",
    "        if window is None:\n",
    "            window = 4\n",
    "        #Determing rolling statistics\n",
    "        rolmean = timeseries.rolling(window=window, center=False).mean()\n",
    "        rolstd = timeseries.rolling(window=window, center=False).std()\n",
    "        \n",
    "        #Plot rolling statistics:\n",
    "        orig = plt.plot(timeseries, color='blue', label='Original')\n",
    "        mean = plt.plot(rolmean, color='red', label='Rolling Mean ({})'.format(window))\n",
    "        std = plt.plot(rolstd, color='black', label='Rolling Std ({})'.format(window))\n",
    "        plt.legend(loc='best')\n",
    "        plt.title('Rolling Mean & Standard Deviation')\n",
    "        plt.show(block=False)\n",
    "    \n",
    "    #Perform Augmented Dickey-Fuller test:\n",
    "    dftest = smt.adfuller(timeseries, maxlag=maxlag, regression=regression, autolag=autolag)\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic',\n",
    "                                             'p-value',\n",
    "                                             '#Lags Used',\n",
    "                                             'Number of Observations Used',\n",
    "                                            ])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    if verbose:\n",
    "        print('Results of Augmented Dickey-Fuller Test:')\n",
    "        print(dfoutput)\n",
    "    return dfoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tsplot(y, lags=None, title='', figsize=(14, 8)):\n",
    "    '''Examine the patterns of ACF and PACF, along with the time series plot and histogram.\n",
    "    \n",
    "    Original source: https://tomaugspurger.github.io/modern-7-timeseries.html\n",
    "    '''\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    layout = (2, 2)\n",
    "    ts_ax   = plt.subplot2grid(layout, (0, 0))\n",
    "    hist_ax = plt.subplot2grid(layout, (0, 1))\n",
    "    acf_ax  = plt.subplot2grid(layout, (1, 0))\n",
    "    pacf_ax = plt.subplot2grid(layout, (1, 1))\n",
    "    \n",
    "    y.plot(ax=ts_ax)\n",
    "    ts_ax.set_title(title)\n",
    "    y.plot(ax=hist_ax, kind='hist', bins=25)\n",
    "    hist_ax.set_title('Histogram')\n",
    "    smt.graphics.plot_acf(y, lags=lags, ax=acf_ax)\n",
    "    smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax)\n",
    "    [ax.set_xlim(0) for ax in [acf_ax, pacf_ax]]\n",
    "    sns.despine()\n",
    "    fig.tight_layout()\n",
    "    return ts_ax, acf_ax, pacf_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_resid_stats(model_results,\n",
    "                      het_method='breakvar',\n",
    "                      norm_method='jarquebera',\n",
    "                      sercor_method='ljungbox',\n",
    "                      verbose=True,\n",
    "                      ):\n",
    "    '''More information about the statistics under the ARIMA parameters table, tests of standardized residuals:\n",
    "    \n",
    "    Test of heteroskedasticity\n",
    "    http://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAXResults.test_heteroskedasticity.html#statsmodels.tsa.statespace.sarimax.SARIMAXResults.test_heteroskedasticity\n",
    "\n",
    "    Test of normality (Default: Jarque-Bera)\n",
    "    http://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAXResults.test_normality.html#statsmodels.tsa.statespace.sarimax.SARIMAXResults.test_normality\n",
    "\n",
    "    Test of serial correlation (Default: Ljung-Box)\n",
    "    http://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAXResults.test_serial_correlation.html\n",
    "    '''\n",
    "    # Re-run the ARIMA model statistical tests, and more. To be used when selecting viable models.\n",
    "    (het_stat, het_p) = model_results.test_heteroskedasticity(het_method)[0]\n",
    "    norm_stat, norm_p, skew, kurtosis = model_results.test_normality(norm_method)[0]\n",
    "    sercor_stat, sercor_p = model_results.test_serial_correlation(method=sercor_method)[0]\n",
    "    sercor_stat = sercor_stat[-1] # last number for the largest lag\n",
    "    sercor_p = sercor_p[-1] # last number for the largest lag\n",
    "\n",
    "    # Run Durbin-Watson test on the standardized residuals.\n",
    "    # The statistic is approximately equal to 2*(1-r), where r is the sample autocorrelation of the residuals.\n",
    "    # Thus, for r == 0, indicating no serial correlation, the test statistic equals 2.\n",
    "    # This statistic will always be between 0 and 4. The closer to 0 the statistic,\n",
    "    # the more evidence for positive serial correlation. The closer to 4,\n",
    "    # the more evidence for negative serial correlation.\n",
    "    # Essentially, below 1 or above 3 is bad.\n",
    "    dw_stat = sm.stats.stattools.durbin_watson(model_results.filter_results.standardized_forecasts_error[0, model_results.loglikelihood_burn:])\n",
    "\n",
    "    # check whether roots are outside the unit circle (we want them to be);\n",
    "    # will be True when AR is not used (i.e., AR order = 0)\n",
    "    arroots_outside_unit_circle = np.all(np.abs(model_results.arroots) > 1)\n",
    "    # will be True when MA is not used (i.e., MA order = 0)\n",
    "    maroots_outside_unit_circle = np.all(np.abs(model_results.maroots) > 1)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Test heteroskedasticity of residuals ({}): stat={:.3f}, p={:.3f}'.format(het_method, het_stat, het_p));\n",
    "        print('\\nTest normality of residuals ({}): stat={:.3f}, p={:.3f}'.format(norm_method, norm_stat, norm_p));\n",
    "        print('\\nTest serial correlation of residuals ({}): stat={:.3f}, p={:.3f}'.format(sercor_method, sercor_stat, sercor_p));\n",
    "        print('\\nDurbin-Watson test on residuals: d={:.2f}\\n\\t(NB: 2 means no serial correlation, 0=pos, 4=neg)'.format(dw_stat))\n",
    "        print('\\nTest for all AR roots outside unit circle (>1): {}'.format(arroots_outside_unit_circle))\n",
    "        print('\\nTest for all MA roots outside unit circle (>1): {}'.format(maroots_outside_unit_circle))\n",
    "    \n",
    "    stat = {'het_method': het_method,\n",
    "            'het_stat': het_stat,\n",
    "            'het_p': het_p,\n",
    "            'norm_method': norm_method,\n",
    "            'norm_stat': norm_stat,\n",
    "            'norm_p': norm_p,\n",
    "            'skew': skew,\n",
    "            'kurtosis': kurtosis,\n",
    "            'sercor_method': sercor_method,\n",
    "            'sercor_stat': sercor_stat,\n",
    "            'sercor_p': sercor_p,\n",
    "            'dw_stat': dw_stat,\n",
    "            'arroots_outside_unit_circle': arroots_outside_unit_circle,\n",
    "            'maroots_outside_unit_circle': maroots_outside_unit_circle,\n",
    "            }\n",
    "    return stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_gridsearch(ts,\n",
    "                     p_min,\n",
    "                     d_min,\n",
    "                     q_min,\n",
    "                     p_max,\n",
    "                     d_max,\n",
    "                     q_max,\n",
    "                     sP_min,\n",
    "                     sD_min,\n",
    "                     sQ_min,\n",
    "                     sP_max,\n",
    "                     sD_max,\n",
    "                     sQ_max,\n",
    "                     trends,\n",
    "                     s=None,\n",
    "                     enforce_stationarity=True,\n",
    "                     enforce_invertibility=True,\n",
    "                     simple_differencing=False,\n",
    "                     plot_diagnostics=False,\n",
    "                     verbose=False,\n",
    "                     filter_warnings=True,\n",
    "                    ):\n",
    "    '''Run grid search of SARIMAX models and save results.\n",
    "    '''\n",
    "    \n",
    "    cols = ['p', 'd', 'q', 'sP', 'sD', 'sQ', 's', 'trend',\n",
    "            'enforce_stationarity', 'enforce_invertibility', 'simple_differencing',\n",
    "            'aic', 'bic',\n",
    "            'het_p', 'norm_p', 'sercor_p', 'dw_stat',\n",
    "            'arroots_gt_1', 'maroots_gt_1',\n",
    "            'datetime_run']\n",
    "\n",
    "    # Initialize a DataFrame to store the results\n",
    "    df_results = pd.DataFrame(columns=cols)\n",
    "\n",
    "    # # Initialize a DataFrame to store the results\n",
    "    # results_bic = pd.DataFrame(index=['AR{}'.format(i) for i in range(p_min,p_max+1)],\n",
    "    #                            columns=['MA{}'.format(i) for i in range(q_min,q_max+1)])\n",
    "\n",
    "    mod_num=0\n",
    "    for trend,p,d,q,sP,sD,sQ in itertools.product(trends,\n",
    "                                                  range(p_min,p_max+1),\n",
    "                                                  range(d_min,d_max+1),\n",
    "                                                  range(q_min,q_max+1),\n",
    "                                                  range(sP_min,sP_max+1),\n",
    "                                                  range(sD_min,sD_max+1),\n",
    "                                                  range(sQ_min,sQ_max+1),\n",
    "                                                  ):\n",
    "        # initialize to store results for this parameter set\n",
    "        this_model = pd.DataFrame(index=[mod_num], columns=cols)\n",
    "\n",
    "        if p==0 and d==0 and q==0:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            model = sm.tsa.SARIMAX(ts,\n",
    "                                   trend=trend,\n",
    "                                   order=(p, d, q),\n",
    "                                   seasonal_order=(sP, sD, sQ, s),\n",
    "                                   enforce_stationarity=enforce_stationarity,\n",
    "                                   enforce_invertibility=enforce_invertibility,\n",
    "                                   simple_differencing=simple_differencing,\n",
    "                                  )\n",
    "            \n",
    "            if filter_warnings is True:\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.filterwarnings(\"ignore\")\n",
    "                    model_results = model.fit(disp=0)\n",
    "            else:\n",
    "                model_results = model.fit()\n",
    "\n",
    "            if verbose:\n",
    "                print(model_results.summary())\n",
    "\n",
    "            if plot_diagnostics:\n",
    "                model_results.plot_diagnostics();\n",
    "\n",
    "            stat = model_resid_stats(model_results,\n",
    "                                     verbose=verbose)\n",
    "\n",
    "            this_model.loc[mod_num, 'p'] = p\n",
    "            this_model.loc[mod_num, 'd'] = d\n",
    "            this_model.loc[mod_num, 'q'] = q\n",
    "            this_model.loc[mod_num, 'sP'] = sP\n",
    "            this_model.loc[mod_num, 'sD'] = sD\n",
    "            this_model.loc[mod_num, 'sQ'] = sQ\n",
    "            this_model.loc[mod_num, 's'] = s\n",
    "            this_model.loc[mod_num, 'trend'] = trend\n",
    "            this_model.loc[mod_num, 'enforce_stationarity'] = enforce_stationarity\n",
    "            this_model.loc[mod_num, 'enforce_invertibility'] = enforce_invertibility\n",
    "            this_model.loc[mod_num, 'simple_differencing'] = simple_differencing\n",
    "\n",
    "            this_model.loc[mod_num, 'aic'] = model_results.aic\n",
    "            this_model.loc[mod_num, 'bic'] = model_results.bic\n",
    "\n",
    "            # this_model.loc[mod_num, 'het_method'] = stat['het_method']\n",
    "            # this_model.loc[mod_num, 'het_stat'] = stat['het_stat']\n",
    "            this_model.loc[mod_num, 'het_p'] = stat['het_p']\n",
    "            # this_model.loc[mod_num, 'norm_method'] = stat['norm_method']\n",
    "            # this_model.loc[mod_num, 'norm_stat'] = stat['norm_stat']\n",
    "            this_model.loc[mod_num, 'norm_p'] = stat['norm_p']\n",
    "            # this_model.loc[mod_num, 'skew'] = stat['skew']\n",
    "            # this_model.loc[mod_num, 'kurtosis'] = stat['kurtosis']\n",
    "            # this_model.loc[mod_num, 'sercor_method'] = stat['sercor_method']\n",
    "            # this_model.loc[mod_num, 'sercor_stat'] = stat['sercor_stat']\n",
    "            this_model.loc[mod_num, 'sercor_p'] = stat['sercor_p']\n",
    "            this_model.loc[mod_num, 'dw_stat'] = stat['dw_stat']\n",
    "            this_model.loc[mod_num, 'arroots_gt_1'] = stat['arroots_outside_unit_circle']\n",
    "            this_model.loc[mod_num, 'maroots_gt_1'] = stat['maroots_outside_unit_circle']\n",
    "\n",
    "            this_model.loc[mod_num, 'datetime_run'] = pd.to_datetime('today').strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            df_results = df_results.append(this_model)\n",
    "            mod_num+=1\n",
    "        except:\n",
    "            continue\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load time series\n",
    "liquor = pd.read_csv('data/liquor.csv', header=0, index_col=0, parse_dates=[0])\n",
    "\n",
    "# Keey only the data from the last 10 years or so\n",
    "liquor = liquor.ix['2007':'2016']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "tsplot(liquor['Value'], title='Liquor Sales (in millions of dollars), 2007-2016', lags=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test stationarity\n",
    "\n",
    "test_stationarity(liquor['Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take first difference of the series\n",
    "test_stationarity(liquor['Value'].diff().dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take log of the series\n",
    "liquor['lnliquor'] = np.log(liquor)\n",
    "\n",
    "test_stationarity(liquor['lnliquor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take first difference of the log series\n",
    "liquor_ln_diff = liquor['lnliquor'].diff()\n",
    "liquor_ln_diff = liquor_ln_diff.dropna()\n",
    "\n",
    "test_stationarity(liquor_ln_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run model grid search\n",
    "\n",
    "p_min = 0\n",
    "d_min = 0\n",
    "q_min = 0\n",
    "p_max = 2\n",
    "d_max = 1\n",
    "q_max = 2\n",
    "\n",
    "sP_min = 0\n",
    "sD_min = 0\n",
    "sQ_min = 0\n",
    "sP_max = 1\n",
    "sD_max = 1\n",
    "sQ_max = 1\n",
    "\n",
    "s=12\n",
    "\n",
    "# trends=['n', 'c']\n",
    "trends=['n']\n",
    "\n",
    "enforce_stationarity=True\n",
    "enforce_invertibility=True\n",
    "simple_differencing=False\n",
    "\n",
    "plot_diagnostics=False\n",
    "\n",
    "verbose=False\n",
    "\n",
    "df_results = model_gridsearch(liquor['Value'],\n",
    "                              p_min,\n",
    "                              d_min,\n",
    "                              q_min,\n",
    "                              p_max,\n",
    "                              d_max,\n",
    "                              q_max,\n",
    "                              sP_min,\n",
    "                              sD_min,\n",
    "                              sQ_min,\n",
    "                              sP_max,\n",
    "                              sD_max,\n",
    "                              sQ_max,\n",
    "                              trends,\n",
    "                              s=s,\n",
    "                              enforce_stationarity=enforce_stationarity,\n",
    "                              enforce_invertibility=enforce_invertibility,\n",
    "                              simple_differencing=simple_differencing,\n",
    "                              plot_diagnostics=plot_diagnostics,\n",
    "                              verbose=verbose,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# choose a model\n",
    "\n",
    "df_results.sort_values(by='bic').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Where to go from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jupyter notebooks, presentations, blog posts\n",
    "\n",
    "- Example notebooks using SARIMAX models:\n",
    "    - SARIMAX introduction\n",
    "        - http://www.statsmodels.org/dev/examples/notebooks/generated/statespace_sarimax_stata.html\n",
    "    - Model selection, missing data\n",
    "        - http://www.statsmodels.org/dev/examples/notebooks/generated/statespace_sarimax_internet.html\n",
    "- \"Time series analysis and forecasting with statsmodels\" presentation, by a statsmodels lead contributor\n",
    "    - https://josef-pkt.github.io/pages/slides/slides_forecasting.slides.html\n",
    "- Time series analysis using Pandas and statsmodels, by a statsmodels lead contributor\n",
    "    - https://tomaugspurger.github.io/modern-7-timeseries.html\n",
    "- Time series analysis using Pandas and statsmodels\n",
    "    - https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/\n",
    "- Simple example of SARIMA forecast (based on the analyticsvidhya.com post)\n",
    "    - http://www.seanabu.com/2016/03/22/time-series-seasonal-ARIMA-model-in-python/\n",
    "\n",
    "\n",
    "#### Free textbooks available online\n",
    "\n",
    "- Forecasting: principles and practice (free textbook, with R code)\n",
    "    - https://www.otexts.org/fpp/\n",
    "- Time Series Analysis and Its Applications: With R Examples (Shumway & Stoffer, EZ time series edition)\n",
    "    - http://www.stat.pitt.edu/stoffer/tsa4/\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
