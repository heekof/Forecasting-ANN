{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/svds_logo.png\" alt=\"SVDS\" width=\"500\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyData San Francisco 2016\n",
    "## Applied Time Series Econometrics in Python (and R) Tutorial\n",
    "### Section 3: ARIMAX Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics in this section include \n",
    "\n",
    "\n",
    "  - 3.1 Model Estimation and Identification\n",
    "  - 3.2 Model Diagnostic Checking\n",
    "    * Define the stationary and invertible conditions for $ARIMA(p,d,q)$ models\n",
    "  - 3.3 Model performance evaluation (in-sample fit)\n",
    "  - 3.4 Forecasting and forecast evaluation \n",
    "  - 3.5 A few words on adding explanatory variables, its use cases, and its practical suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# TSA from Statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.tsa.api as smt\n",
    "\n",
    "# Display and Plotting\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x) # pandas\n",
    "np.set_printoptions(precision=5, suppress=True) # numpy\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# seaborn plotting style\n",
    "sns.set(style='ticks', context='poster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "** Read a series stored in a csv file. ** This is the same series we used in *Exercise 2*.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the csv file containing the series for the analysis\n",
    "# This is the file we just analyzed in Exercise 2\n",
    "\n",
    "filename_ts = 'data/series1.csv'\n",
    "ts_df = pd.read_csv(filename_ts, index_col=0, parse_dates=[0])\n",
    "\n",
    "n_sample = ts_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(ts_df.shape)\n",
    "print(ts_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Model Identification (ARIMA Model Determination)\n",
    "\n",
    "1. Determine the *degree of differencing*, $d$\n",
    "\n",
    "2. Study the patterns of the ACF and PACF of the appropriately differenced series: $\\omega_t = (1-B)^d z_t$, as these autocorrelation functions will provide indication for the choice of the order of autoregressive and the moving average components.  While we did not have enough time in this tutorial, it is very beneficial to study the *theoretical* ACF and PACF of the autoregressive, moving average, and the mixed autoregressive and moving average processes.\n",
    "\n",
    "3. The table below summarize the patterns of the ACF and PACF associated with the $AR(p)$, $MA(q)$, and $ARMA(p,q)$ processes:\n",
    "\n",
    "|  Process      |          ACF         |          PACF        |\n",
    "|---------------|:--------------------:|:--------------------:|\n",
    "| **AR(p)**     |    tails off         | cutoff after lag $p$ |\n",
    "| **MA(q)**     | cutoff after lag $q$ |    tails off         |\n",
    "| **ARMA(p,q)** |    tails off         |    tails off         |\n",
    "\n",
    "4. In general, the ACF of an autoregressive process is similar to the PACF of a moving average process, and vice versa.\n",
    "5. Keep in mind that these are theoretical properties. In practice, the estimated sample ACF and PACF can come with large variances, deviating from the underlying theoretical behavior. As such, it is prudent to recognize that these are  but broad characteristics, and it is quite possible that several candidate models are narrowed down and will need to be investigaged further in the later stage of the modeling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a training sample and testing sample before analyzing the series\n",
    "\n",
    "n_train=int(0.95*n_sample)+1\n",
    "n_forecast=n_sample-n_train\n",
    "#ts_df\n",
    "ts_train = ts_df.iloc[:n_train]['value']\n",
    "ts_test = ts_df.iloc[n_train:]['value']\n",
    "print(ts_train.shape)\n",
    "print(ts_test.shape)\n",
    "print(\"Training Series:\", \"\\n\", ts_train.tail(), \"\\n\")\n",
    "print(\"Testing Series:\", \"\\n\", ts_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tsplot(y, lags=None, title='', figsize=(14, 8)):\n",
    "    '''Examine the patterns of ACF and PACF, along with the time series plot and histogram.\n",
    "    \n",
    "    Source: https://tomaugspurger.github.io/modern-7-timeseries.html\n",
    "    '''\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    layout = (2, 2)\n",
    "    ts_ax   = plt.subplot2grid(layout, (0, 0))\n",
    "    hist_ax = plt.subplot2grid(layout, (0, 1))\n",
    "    acf_ax  = plt.subplot2grid(layout, (1, 0))\n",
    "    pacf_ax = plt.subplot2grid(layout, (1, 1))\n",
    "    \n",
    "    y.plot(ax=ts_ax)\n",
    "    ts_ax.set_title(title)\n",
    "    y.plot(ax=hist_ax, kind='hist', bins=25)\n",
    "    hist_ax.set_title('Histogram')\n",
    "    smt.graphics.plot_acf(y, lags=lags, ax=acf_ax)\n",
    "    smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax)\n",
    "    [ax.set_xlim(0) for ax in [acf_ax, pacf_ax]]\n",
    "    sns.despine()\n",
    "    fig.tight_layout()\n",
    "    return ts_ax, acf_ax, pacf_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tsplot(ts_train, title='A Given Training Series', lags=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Observations from the sample ACF and sample PACF (based on first 20 lags) **\n",
    "\n",
    "- The sample autocorrelation gradually tails off.\n",
    "- The sample partial autocorrelation does not exactly cut off at some lag $p$ but does not exactly tail off either.\n",
    "- Based on these observations, we could attempt an ARIMA(2,0,0) model as a starting point, although other orders could serve as candidates as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Up until this point in the tutorial, statsmodels 0.6.1 is fine.\n",
    "# From here on, we need an updated version of statsmodels 0.8.0rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Uncomment to install\n",
    "# !pip install --pre statsmodels --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Model Estimation\n",
    "\n",
    "# Fit the model\n",
    "arima200 = sm.tsa.SARIMAX(ts_train, order=(2,0,0))\n",
    "model_results = arima200.fit()\n",
    "model_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Digression:\n",
    "\n",
    "* In practice, one could *search* over a few models using the visual clues above as a starting point.  \n",
    "* The code below gives one such example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "p_min = 0\n",
    "d_min = 0\n",
    "q_min = 0\n",
    "p_max = 4\n",
    "d_max = 0\n",
    "q_max = 4\n",
    "\n",
    "# Initialize a DataFrame to store the results\n",
    "results_bic = pd.DataFrame(index=['AR{}'.format(i) for i in range(p_min,p_max+1)],\n",
    "                           columns=['MA{}'.format(i) for i in range(q_min,q_max+1)])\n",
    "\n",
    "for p,d,q in itertools.product(range(p_min,p_max+1),\n",
    "                               range(d_min,d_max+1),\n",
    "                               range(q_min,q_max+1)):\n",
    "    if p==0 and d==0 and q==0:\n",
    "        results_bic.loc['AR{}'.format(p), 'MA{}'.format(q)] = np.nan\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        model = sm.tsa.SARIMAX(ts_train, order=(p, d, q),\n",
    "                               #enforce_stationarity=False,\n",
    "                               #enforce_invertibility=False,\n",
    "                              )\n",
    "        results = model.fit()\n",
    "        results_bic.loc['AR{}'.format(p), 'MA{}'.format(q)] = results.bic\n",
    "    except:\n",
    "        continue\n",
    "results_bic = results_bic[results_bic.columns].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax = sns.heatmap(results_bic,\n",
    "                 mask=results_bic.isnull(),\n",
    "                 ax=ax,\n",
    "                 annot=True,\n",
    "                 fmt='.2f',\n",
    "                 );\n",
    "ax.set_title('BIC');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Alternative model selection method, limited to only searching AR and MA parameters\n",
    "\n",
    "train_results = sm.tsa.arma_order_select_ic(ts_train, ic=['aic', 'bic'], trend='nc', max_ar=4, max_ma=4)\n",
    "\n",
    "print('AIC', train_results.aic_min_order)\n",
    "print('BIC', train_results.bic_min_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Model Diagnostic Checking\n",
    "\n",
    "* Conduct visual inspection of the residual plots\n",
    "* Residuals of a well-specified ARIMA model should mimic *Gaussian white noises*: the residuals should be uncorrelated and distributed approximated normally with mean zero and variance $n^{-1}$\n",
    "* Apparent patterns in the standardized residuals and the estimated ACF of the residuals give an indication that the model need to be re-specified\n",
    "* The *results.plot_diagnostics()* function conveniently produce several plots to facilitate the investigation.\n",
    "* The estimation results also come with some statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Residual Diagnostics\n",
    "# The plot_diagnostics function associated with the estimated result object produce a few plots that allow us \n",
    "# to examine the distribution and correlation of the estimated residuals\n",
    "\n",
    "model_results.plot_diagnostics(figsize=(16, 12));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Formal testing\n",
    "\n",
    "** More information about the statistics under the parameters table, tests of standardized residuals **\n",
    "\n",
    "#### Test of heteroskedasticity\n",
    "- http://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAXResults.test_heteroskedasticity.html#statsmodels.tsa.statespace.sarimax.SARIMAXResults.test_heteroskedasticity\n",
    "\n",
    "#### Test of normality (Jarque-Bera)\n",
    "- http://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAXResults.test_normality.html#statsmodels.tsa.statespace.sarimax.SARIMAXResults.test_normality\n",
    "\n",
    "#### Test of serial correlation (Ljung-Box)\n",
    "- http://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAXResults.test_serial_correlation.html#statsmodels.tsa.statespace.sarimax.SARIMAXResults.test_serial_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Re-run the above statistical tests, and more. To be used when selecting viable models.\n",
    "\n",
    "het_method='breakvar'\n",
    "norm_method='jarquebera'\n",
    "sercor_method='ljungbox'\n",
    "\n",
    "(het_stat, het_p) = model_results.test_heteroskedasticity(het_method)[0]\n",
    "norm_stat, norm_p, skew, kurtosis = model_results.test_normality(norm_method)[0]\n",
    "sercor_stat, sercor_p = model_results.test_serial_correlation(method=sercor_method)[0]\n",
    "sercor_stat = sercor_stat[-1] # last number for the largest lag\n",
    "sercor_p = sercor_p[-1] # last number for the largest lag\n",
    "\n",
    "# Run Durbin-Watson test on the standardized residuals.\n",
    "# The statistic is approximately equal to 2*(1-r), where r is the sample autocorrelation of the residuals.\n",
    "# Thus, for r == 0, indicating no serial correlation, the test statistic equals 2.\n",
    "# This statistic will always be between 0 and 4. The closer to 0 the statistic,\n",
    "# the more evidence for positive serial correlation. The closer to 4,\n",
    "# the more evidence for negative serial correlation.\n",
    "# Essentially, below 1 or above 3 is bad.\n",
    "dw = sm.stats.stattools.durbin_watson(model_results.filter_results.standardized_forecasts_error[0, model_results.loglikelihood_burn:])\n",
    "\n",
    "# check whether roots are outside the unit circle (we want them to be);\n",
    "# will be True when AR is not used (i.e., AR order = 0)\n",
    "arroots_outside_unit_circle = np.all(np.abs(model_results.arroots) > 1)\n",
    "# will be True when MA is not used (i.e., MA order = 0)\n",
    "maroots_outside_unit_circle = np.all(np.abs(model_results.maroots) > 1)\n",
    "\n",
    "print('Test heteroskedasticity of residuals ({}): stat={:.3f}, p={:.3f}'.format(het_method, het_stat, het_p));\n",
    "print('\\nTest normality of residuals ({}): stat={:.3f}, p={:.3f}'.format(norm_method, norm_stat, norm_p));\n",
    "print('\\nTest serial correlation of residuals ({}): stat={:.3f}, p={:.3f}'.format(sercor_method, sercor_stat, sercor_p));\n",
    "print('\\nDurbin-Watson test on residuals: d={:.2f}\\n\\t(NB: 2 means no serial correlation, 0=pos, 4=neg)'.format(dw))\n",
    "print('\\nTest for all AR roots outside unit circle (>1): {}'.format(arroots_outside_unit_circle))\n",
    "print('\\nTest for all MA roots outside unit circle (>1): {}'.format(maroots_outside_unit_circle))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Model performance evaluation (in-sample fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(nrows=1, ncols=1, figsize=(12, 8))\n",
    "    \n",
    "ax1.plot(ts_train, label='In-sample data', linestyle='-')\n",
    "# subtract 1 only to connect it to previous point in the graph\n",
    "ax1.plot(ts_test, label='Held-out data', linestyle='--')\n",
    "\n",
    "# yes DatetimeIndex\n",
    "pred_begin = ts_train.index[model_results.loglikelihood_burn]\n",
    "pred_end = ts_test.index[-1]\n",
    "pred = model_results.get_prediction(start=pred_begin.strftime('%Y-%m-%d'),\n",
    "                                    end=pred_end.strftime('%Y-%m-%d'))\n",
    "pred_mean = pred.predicted_mean\n",
    "pred_ci = pred.conf_int(alpha=0.05)\n",
    "\n",
    "ax1.plot(pred_mean, 'r', alpha=.6, label='Predicted values')\n",
    "ax1.fill_between(pred_ci.index,\n",
    "                 pred_ci.iloc[:, 0],\n",
    "                 pred_ci.iloc[:, 1], color='k', alpha=.2)\n",
    "\n",
    "ax1.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rmse(y, y_hat):\n",
    "    '''Root Mean Square Error\n",
    "    https://en.wikipedia.org/wiki/Root-mean-square_deviation\n",
    "    '''\n",
    "    mse = np.mean((y - y_hat)**2)\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "def get_mape(y, y_hat):\n",
    "    '''Mean Absolute Percent Error\n",
    "    https://en.wikipedia.org/wiki/Mean_absolute_percentage_error\n",
    "    '''\n",
    "    perc_err = (100*(y - y_hat))/y\n",
    "    return np.mean(abs(perc_err))\n",
    "\n",
    "def get_mase(y, y_hat):\n",
    "    '''Mean Absolute Scaled Error\n",
    "    https://en.wikipedia.org/wiki/Mean_absolute_scaled_error\n",
    "    '''\n",
    "    abs_err = abs(y - y_hat)\n",
    "    dsum=sum(abs(y[1:] - y_hat[1:]))\n",
    "    t = len(y)\n",
    "    denom = (1/(t - 1))* dsum\n",
    "    return np.mean(abs_err/denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmse = get_rmse(ts_train, pred_mean.ix[ts_train.index])\n",
    "print(\"RMSE: \", rmse)\n",
    "\n",
    "mape = get_mape(ts_train, pred_mean.ix[ts_train.index])\n",
    "print(\"MAPE: \", mape)\n",
    "\n",
    "mase = get_mase(ts_train, pred_mean.ix[ts_train.index])\n",
    "print(\"MASE: \", mase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Forecasting and forecast evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rmse = get_rmse(ts_test, pred_mean.ix[ts_test.index])\n",
    "print(rmse)\n",
    "\n",
    "mape = get_mape(ts_test, pred_mean.ix[ts_test.index])\n",
    "print(mape)\n",
    "\n",
    "mase = get_mase(ts_test, pred_mean.ix[ts_test.index])\n",
    "print(mase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exericse 3:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the csv file containing the series for the analysis\n",
    "\n",
    "# Step 1a: Read the data series\n",
    "filename_ts = 'data/series2.csv'\n",
    "series2_df = pd.read_csv(filename_ts, index_col=0, parse_dates=[0])\n",
    "\n",
    "# Step 1b: Create the training and testing series before analyzing the series\n",
    "\n",
    "n_sample = series2_df.shape[0]\n",
    "\n",
    "n_train=int(0.95*n_sample)+1\n",
    "n_forecast=n_sample-n_train\n",
    "\n",
    "series2_train = series2_df.iloc[:n_train]['value']\n",
    "series2_test  = series2_df.iloc[n_train:]['value']\n",
    "print(series2_train.shape)\n",
    "print(series2_test.shape)\n",
    "print(\"Training Series:\", \"\\n\", series2_train.tail(), \"\\n\")\n",
    "print(\"Testing Series:\", \"\\n\", series2_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 2a: Examine the basic structure of the data\n",
    "print(\"Data shape:\", series2_train.shape, \"\\n\")\n",
    "print(\"First 5 observations of the data series:\", \"\\n\", series2_train.head(), \"\\n\")\n",
    "print(\"Last 5 observations of the data series:\", \"\\n\", series2_train.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 2b: Examine the series and use the visuals as clues for the choice of the orders of the ARIMA model\n",
    "# Choose the number of lags you would like to display. Pick a number that is at least 20.\n",
    "\n",
    "# tsplot(series2_train, title='Series 2', lags=?);\n",
    "\n",
    "tsplot(series2_train, title='Series 2', lags=YOUR_CODE_HERE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 2c: Conduct any necessary transformations (such as natural log, difference, difference in natural log, etc )\n",
    "# and repeat Step 2b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 3: Estimate an non-Seasonal ARIMA model\n",
    "# Note: you will have to pick the orders (p,d,q)\n",
    "\n",
    "# ex3_mod = sm.tsa.statespace.SARIMAX(series2_train, order=(?,?,?))\n",
    "ex3_mod = sm.tsa.statespace.SARIMAX(series2_train, order=())\n",
    "ex3_arima_fit = ex3_mod.fit()\n",
    "print(ex3_arima_fit.summary())\n",
    "\n",
    "# Discuss your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 4: Conduct model diagnostic check\n",
    "\n",
    "ex3_arima_fit.plot_diagnostics(figsize=(16, 12));\n",
    "\n",
    "# Discuss these plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 5: Do a 5-step ahead forecast\n",
    "\n",
    "# ... codes need to be adjusted\n",
    "\n",
    "fig, ax1 = plt.subplots(nrows=1, ncols=1, figsize=(12, 8))\n",
    "    \n",
    "ax1.plot(series2_train, label='In-sample data', linestyle='-')\n",
    "# subtract 1 only to connect it to previous point in the graph\n",
    "ax1.plot(series2_test, label='Held-out data', linestyle='--')\n",
    "\n",
    "# yes DatetimeIndex\n",
    "pred_begin = series2_train.index[ex3_arima_fit.loglikelihood_burn]\n",
    "pred_end = series2_test.index[-1]\n",
    "pred = ex3_arima_fit.get_prediction(start=pred_begin.strftime('%Y-%m-%d'),\n",
    "                                    end=pred_end.strftime('%Y-%m-%d'))\n",
    "pred_mean = pred.predicted_mean\n",
    "pred_ci = pred.conf_int(alpha=0.05)\n",
    "\n",
    "ax1.plot(pred_mean, 'r', alpha=.6, label='Predicted values')\n",
    "ax1.fill_between(pred_ci.index,\n",
    "                 pred_ci.iloc[:, 0],\n",
    "                 pred_ci.iloc[:, 1], color='k', alpha=.2)\n",
    "\n",
    "ax1.legend(loc='best');\n",
    "\n",
    "## Discuss the results.  How does your forecast look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
